---
title: "Clustering Congressional Districts"
author: "MHickey"
date: "12/8/2020"
output: html_document
---

# Clustering Applications for Drawing Congressional Districts

Load Libraries

```{r}
library(dplyr)
library(ggplot2)
library(magrittr)
```


The data we will be clustering is from the US Census Bureau (https://www.census.gov/geographies/reference-files/time-series/geo/centers-population.html). It represents the distribution of Census Tracts in the state of Wisconsin. For the purposes of this assignment, we can make the simplifying assumption that each Census tract is associated with an equal population size. While this assumption is inaccurate, it sufficiently reduces the data size and computational time to allow for a reasonable timeframe for completing the assignment.

```{r}
Data <- read.csv("Wisconsin.csv")
head(Data, 5) # Preview first 8 rows of data
print(paste0("Data consists of ", nrow(Data), " unique Wisconsin Census Tracts"))
```

User Defined Functions
```{r, echo = F}

blurringMeanShiftOperator <- function( X, h=1, kernel="epanechnikovKernel" ){
	n.curves <- ncol( X )
	
	## compute distances
	distances <- as.matrix( dist( t( X ), diag=TRUE, upper=TRUE ) )
	
	## scale by bandwidth
	scaled.distances <- distances / h
	
	## evaluate kernel
	kernel <- get( kernel )
	kernel.values <- matrix( kernel( scaled.distances ), nrow=n.curves,
	ncol=n.curves ) 
	
	## weights denominators
	total.sum <- colSums( kernel.values )
	
	## weights
	kernel.weights <- kernel.values / total.sum

	## update
	new.X <- X%*%t( kernel.weights )
	
	output <- new.X
	
	return( new.X )
	
}

blurringMeanShiftAlgorithm <- function( X, h=NULL,
kernel="epanechnikovKernel", tol.stop=1e-6, max.iter=100 ){
	
	if( is.null( h ) ){
		
		h <- quantile( dist( t( X ) ), 0.3 )
		
	}
	
	close.enough <- FALSE
	
	old.X <- X
	
	iter <- 0
	not.converged <- FALSE
	
	## while the largest update corresponds to a shift
	## larger than 'tol.stop' and while number of iterations
	## is smaller than 'max.iter'
	while( !close.enough ){
		
		## apply blurring mean-shift operator and update
		iter <- iter + 1
		
		new.X <- blurringMeanShiftOperator( X=old.X, h=h, kernel=kernel )
		
		distance <- max( sqrt( colSums( old.X - new.X )^2 ) )
		
		old.X <- new.X
		
		close.enough <- ( distance < tol.stop )
		
		if( iter >= max.iter ){
			
			not.converged <- TRUE
			break
			
		}
		
	}
	
	if( not.converged ){
		
		if( kernel == "epanechnikovKernel"){
			
			warning( "Reached maximum number of iterations (", 
			as.character( max.iter),"). The algorithm ",
			"didn't converge. Try increasing max.iter." )
			
		} else{

			warning( "Reached maximum number of iterations (", 
			as.character( max.iter),"). The algorithm ",
			"didn't converge. Try kernel=\"epanechnikovKernel\"." )
			
		}
		
	} else{

		message( "Blurring mean-shift algorithm ran successfully.\n")
			
	}
	
	return( new.X )
	
}

# Meanshift Clustering Function
bmsClustering <- function( X, h=NULL, kernel="epanechnikovKernel",
tol.stop=1e-6, max.iter=100, tol.epsilon=1e-3 ){
	
	# minimal input checking
	X <- as.matrix( X )
	max.iter <- as.integer( max.iter )
	
	if( ncol( X ) <= 1 ){
		
		message( "The input matrix X has only one column: ",
		"returning input.")
		return( X )
	}

	if( !is.element( kernel, paste( c( "epanechnikov", "cubic", 
	"gaussian", "exponential"), "Kernel", sep="" ) ) ){
		
		stop( "Invalid kernel name.")
		
	}
	
	if( !is.null( h ) && h <= 0 ){
		
		stop( "The bandwidth must be strictly positive." )
				
	}
	
	if( max.iter <= 0 ){
		
		stop( "The maximum number of iterations must be a positive ",
		"integer." )
		
	}
	
	if( tol.stop <= 0 || tol.epsilon <= 0 ){
		
		stop( "All tolerances must be strictly positive.")
		
	}
	
	## run blurring mean-shift algorithm
	message( "\nRunning blurring mean-shift algorithm...\n" )
	
	blurring.mean.shift.algorithm <- blurringMeanShiftAlgorithm( X=X,
	h=h, kernel=kernel, tol.stop=tol.stop, max.iter=max.iter )
	
	## find connected components
	message( "Finding clusters..." )
	output <- connectedComponents( X=blurring.mean.shift.algorithm,
	tol.epsilon=tol.epsilon )
	
	invisible( output )

}


gaussianKernel <- function( x ){
	
	## function to evaluate the asymmetric gaussian kernel	
	computeGaussianKernel <- function( y ){
	
		if( 0 <= y ){
		
			value <- 2 / 0.388 * dnorm( y / 0.388 )
		
		} else{
		
			value <- 0
		
		}
	
		return( value )
	
	}
	
	output <- sapply( x, computeGaussianKernel )
	
	return( output )
		
}


###

exponentialKernel <- function( x ){
	
	## function to evaluate the asymmetric exponential kernel	
	computeExponentialKernel <- function( y ){
	
		if( 0 <= y ){
		
			value <- dexp( y, rate=4.61 )
		
		} else{
		
			value <- 0
		
		}
	
		return( value )
	
	}
	
	output <- sapply( x, computeExponentialKernel )
	
	return( output )
		
}

###

cubicKernel <- function( x ){
	
	## function to evaluate the asymmetric cubic kernel	
	computeCubicKernel <- function( y ){
	
		if( 0 <= y && y<= 1 ){
		
			value <- 4 * ( 1 - y )^3
		
		} else{
		
			value <- 0
		
		}
	
		return( value )
	
	}
	
	output <- sapply( x, computeCubicKernel )
	
	return( output )
		
}

###

epanechnikovKernel <- function( x ){
	
	## function to evaluate the asymmetric Epanechnikov kernel	
	computeEpanechnikovKernel <- function( y ){
	
		if( 0 <= y && y<= 1 ){
		
			value <- 3 / 2 * ( 1 - y^2 )
		
		} else{
		
			value <- 0
		
		}
	
		return( value )
	
	}
	
	output <- sapply( x, computeEpanechnikovKernel )
	
	return( output )
		
}

###

distanceFunction <- function( x, y ){
	
	## function to compute the standard euclidean distance
	output <- sqrt( sum( ( x - y )^2 ) )
	
	return( output )
	
}

###

connectedComponents <- function( X, tol.epsilon=1e-3 ){

	N <- ncol( X )
	
	## initialize components matrix
	C <- X
	
	## initialize components vector
	labels <- vector( mode="integer", length=N )
	
	K <- 1 
	labels[1] <- 1
	C[,1] <- X[,1]
	
	# pb <- txtProgressBar( min=0, max=N, style=3 )
	
	## efficient connected component algorithm
	for( n in 2:N ){
		
		assigned <- FALSE
				
		for( k in 1:K ){
			
			distance <- distanceFunction( X[,n], C[,k] )
			
			if( distance < tol.epsilon ){
				
				labels[n] <- k
				assigned <- TRUE
				break
				
			}
			
		}
		
		if( !assigned ){
			
			K <- K + 1
			labels[n] <- K
			C[,K] <- X[,n]
			
		}
		
		# setTxtProgressBar( pb, n )
		
	}
	
	C <- as.matrix( C[,1:K] )
	colnames( C ) <- paste( "mode", 1:K, sep="" )
	
	labels <- as.integer( labels )
	
	output <- list( components=C, labels=labels )
	
	# close( pb )
	
	message( "\nThe algorithm found ", as.character( K ),
	" clusters.\n")
	
	return( output )
		
}


```


The first 8 rows of the dataset are previewed above. Each row represents an individual Cencus tract and has a unique combination of the first three columns (State, County, and Tract Code). The LATITUDE and LONGITUDE values represent the "center of gravity" of each Census tract.

In the next code block, we clean and scale the data.

```{r}
# Reducing data set to only clustering parameters
CongressData <- Data %>% transmute(LATITUDE, LONGITUDE)

# Scaling Data
CongressData$LATITUDE <- (CongressData$LATITUDE-mean(CongressData$LATITUDE))/sd(CongressData$LATITUDE)
CongressData$LONGITUDE <- (CongressData$LONGITUDE-mean(CongressData$LONGITUDE))/sd(CongressData$LONGITUDE)
```

# Drawing Congressional Districts with MeanShift Clustering

First, we will investigate the Wisconsin Congressional map using the MeanShift Algorithm. The below code can be run as written. Note, this may take a minute or longer to run.

```{r, fig.height=8, fig.width=10}
# Inputs
K <- 8
X <- t(CongressData)
h <- .8

kernel <- "epanechnikovKernel" #"epanechnikovKernel", "cubicKernel", "gaussianKernel", "exponentialKernel"
tol.stop <- 1e-10
tol.epsilon <- 1e-04
max.iter <- 20


Congress_clust_ms <- bmsClustering(X = X,
                         h=h,
                         kernel = kernel,
                         tol.stop = tol.stop,
                         tol.epsilon = tol.epsilon,
                         max.iter = max.iter)

# Unscale data for plotting and extract clusters associated with each Census tract
PlotCongressDataMS <- Data %>% transmute(LATITUDE, LONGITUDE, POPULATION)
PlotCongressDataMS$cluster <- Congress_clust_ms$labels

ggplot() +
    geom_point(data = PlotCongressDataMS,
               aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster)),
               alpha = 1/2, size = 1) +
    #geom_point(data = Centers,
     #          aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster)),
      #         alpha = 1/2, size = 4) +
    labs(x = "Longitude (deg)", y = "Latitude (deg)", title = "Wisconsin Congressional Districts",
         subtitle = "Mean Shift Clustering",
         color = "Clustered District") +
    theme_minimal()
```

The algorithm has converged on a solution with 8 Congressional districts. However, some districts appear to have far more Census tracts than others. Recall that our application requires districts/clusters with roughly equal populations. Let's plot a bar-chart of each district by number of Census Tracts (we assume this is equivalent to population count).

```{r}
ggplot(PlotCongressDataMS %>% group_by(cluster) %>% summarize(Count = n())) +
    geom_col(aes(x = as.factor(cluster), y = Count, fill = as.factor(cluster))) +
    labs(x = "Clustered District", y = "Number of Census Tracts") + 
    theme_minimal() +
    theme(legend.position="none") +
    scale_fill_brewer(palette = "Dark2")
```

We can see that District 3 has more population than all other clusters combined. Unfortunately, this solution is not viable for our application.

# Drawing Congressional Districts with K-Means Clustering

Next, we apply the K-Means algorithem in order to cluster the Census data into proposed Congressional districts.

```{r}
# Set Input Values
set.seed(0)
K = 8
IterMax = 5

# Run K-Means Algorithm
CongressCluster <- kmeans(CongressData, centers = K, iter.max = IterMax)

# Unscale data for plotting and extract clusters associated with each Census tract
PlotCongressData <- Data %>% transmute(LATITUDE, LONGITUDE, POPULATION)
PlotCongressData$cluster <- CongressCluster$cluster

# Create dataframe for plotting cluster centers
Centers <- as.data.frame(CongressCluster$centers)
Centers$LATITUDE <- Centers$LATITUDE*sd(PlotCongressData$LATITUDE) + mean(PlotCongressData$LATITUDE)
Centers$LONGITUDE <- Centers$LONGITUDE*sd(PlotCongressData$LONGITUDE) + mean(PlotCongressData$LONGITUDE)
Centers$cluster <- 1:K
```

Next, the clustering results are plotted:

```{r, fig.height=8, fig.width=10}
ggplot() +
    geom_point(data = PlotCongressData,
               aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster)),
               alpha = 1/2, size = 1) +
    geom_point(data = Centers,
               aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster)),
               alpha = 1/2, size = 4) +
    labs(x = "Longitude (deg)", y = "Latitude (deg)", title = "Wisconsin Congressional Districts",
         subtitle = "K-Means Clustering",
         color = "Clustered District") + 
    theme_minimal() +
    scale_color_brewer(palette = "Dark2")
```

The resulting districts vary greatly in terms of the number of constituent Census tracts. Similar to the results of the Mean Shift algorithm, this presents a problem, because our application requires districts of roughly equal populations.

```{r}
ggplot(PlotCongressData %>% group_by(cluster) %>% summarize(Count = n())) +
    geom_col(aes(x = as.factor(cluster), y = Count, fill = as.factor(cluster))) +
    labs(x = "Clustered District", y = "Number of Census Tracts (Population)") + 
    theme_minimal() +
    theme(legend.position="none") +
    scale_fill_brewer(palette = "Dark2")
```

Shown above, District 4 (including much of what appears to be the Milwaukee metropolitan area) contains a vastly greater population than any other clustered district. K-Means has been shown to generate a logical and unbiased set of clusters of census tracts, it fails to produce Congressional districts with roughly equal populations.

By design, neither K-Means nor Mean Shift ensure equal-sized clusters. In many clustering applications, such as the example explored at the beginning of this assignment, the natural clusters in the data are very different in size.

# Drawing Congressional Districts with Equal-Sized K-Means Clustering

In this section, we alter the K-Means clustering algorithm in order to ensure roughly equal-sized clusters. An algorithm has been coded below, that is based on the algorithm developed by Schramm and DeZewarte in a June 2019 post on R Views (a popular R Community Blog).

[https://rviews.rstudio.com/2019/06/13/equal-size-kmeans/]

In short, the algorithm works in the following steps:

- 1) Generate results of K-Means Clustering on data set as the initial cluster centers.

- 2) Use the resulting cluster centers to re-assign every data point one at a time. This is done by rotating through each cluster in rounds and assigning the nearest data point (similar to "team captains" in a pickup sports game)

- 3) Derive the new cluster centers by using the K-Means algorithm with K = 1 for each individual cluster

- 4) Repeat steps 2-3 until convergence is achieved or maximum iterations has been reached

The code for Equal-Sized K-Means is below. Note, this can take a minute or so to run.

```{r}
# Based on code from https://rviews.rstudio.com/2019/06/13/equal-size-kmeans/

# Set Seed so that initial cluster centers are always the same
set.seed(1)

# Set Input Parameters
k = 8
iter = 20

# We start off the algorithm with the results of K-Means using iter.max = 100
kdat = as.data.frame(CongressData)
kdat %>% kmeans(k, iter.max = 100) -> kclust

# Create function for deriving distance between census tracts
kdist = function(x1, y1, x2, y2){
  # Note: distance is calculated via pythagorean theorem. A more accurate method would be the Great Circle distance.
  # Given the scale of our data, and the limited regoin, euclidian distance is a suitable approximation
  sqrt((x1-x2)^2 + (y1-y2)^2) }

centers = kclust$centers %>% as.data.frame()
converged <- 0


for (looper in 1:iter) {
    
    # Determine distance from each district to each cluster center
    kdat %<>% 
      mutate(D1 = kdist(LATITUDE, LONGITUDE, centers[1,1], centers[1,2]),
             D2 = kdist(LATITUDE, LONGITUDE, centers[2,1], centers[2,2]),
             D3 = kdist(LATITUDE, LONGITUDE, centers[3,1], centers[3,2]),
             D4 = kdist(LATITUDE, LONGITUDE, centers[4,1], centers[4,2]),
             D5 = kdist(LATITUDE, LONGITUDE, centers[5,1], centers[5,2]),
             D6 = kdist(LATITUDE, LONGITUDE, centers[6,1], centers[6,2]),
             D7 = kdist(LATITUDE, LONGITUDE, centers[7,1], centers[7,2]),
             D8 = kdist(LATITUDE, LONGITUDE, centers[8,1], centers[8,2]))

    kdat$assigned = 0
    kdat$index = 1:nrow(kdat)
    working = kdat
    FirstRound = nrow(kdat) - (nrow(kdat) %% k)

    for(i in 1:FirstRound){ 
      #cluster counts can be off by 1 due to uneven multiples of k. 
      j = if(i %% k == 0) k else (i %% k)
      itemloc = 
        working$index[which(working[,(paste0("D", j))] ==
        min(working[,(paste0("D",j))]))[1]]
      kdat$assigned[kdat$index == itemloc] = j
      working %<>% filter(!index == itemloc)
    }

        for(i in 1:nrow(working)){
          #these leftover points get assigned to whoever's closest, without regard to k
          kdat$assigned[kdat$index ==
                          working$index[i]] = 
            which(working[i,3:(k+2)] == min(working[i, 3:(k+2)])) 
        }

        # Use K-Means (K=1) for each cluster to determine the new cluster centers
        NewCenters <- kdat %>% filter(assigned == 1) %>% 
                                select(LATITUDE, LONGITUDE) %>%
                                kmeans(1) %$% centers %>%
        rbind(kdat %>% 
                                filter(assigned == 2) %>%
                                select(LATITUDE, LONGITUDE) %>%
                                kmeans(1) %$% centers) %>%
        rbind(kdat %>% 
                                filter(assigned == 3) %>%
                                select(LATITUDE, LONGITUDE) %>%
                                kmeans(1) %$% centers) %>%
        rbind(kdat %>%
                                filter(assigned == 4) %>%
                                select(LATITUDE, LONGITUDE) %>%
                                kmeans(1) %$% centers) %>%
        rbind(kdat %>% 
                                filter(assigned == 5) %>%
                                select(LATITUDE, LONGITUDE) %>%
                                kmeans(1) %$% centers) %>%
        rbind(kdat %>%
                                filter(assigned == 6) %>%
                                select(LATITUDE, LONGITUDE) %>%
                                kmeans(1) %$% centers) %>%
        rbind(kdat %>% 
                                filter(assigned == 7) %>%
                                select(LATITUDE, LONGITUDE) %>%
                                kmeans(1) %$% centers) %>%
        rbind(kdat %>%
                                filter(assigned == 8) %>%
                                select(LATITUDE, LONGITUDE) %>%
                                kmeans(1) %$% centers) %>%
        as.data.frame()
    
        # Additional logic to account for misclustered outliers far away from any cluster
        kdat %<>% mutate(assignedDist = ifelse(assigned == 1, D1,
                                          ifelse(assigned == 2, D2,
                                                ifelse(assigned == 3, D3,
                                                      ifelse(assigned == 4, D4,
                                                            ifelse(assigned == 5, D5,
                                                                  ifelse(assigned == 6, D6,
                                                                        ifelse(assigned == 7, D7, D8)))))))) %>%
                  rowwise() %>%
                  mutate(minDist = min(D1, D2, D3, D4, D5, D6, D7, D8)) %>%
                  ungroup() %>%
                  mutate(minDistClust = ifelse(minDist == D1, 1,
                                          ifelse(minDist == D2, 2,
                                                ifelse(minDist == D3, 3,
                                                      ifelse(minDist == D4, 4,
                                                            ifelse(minDist == D5, 5,
                                                                  ifelse(minDist == D6, 6,
                                                                        ifelse(minDist == D7, 7, 8))))))))

        kdat %<>% mutate(assigned = ifelse(assignedDist > 2.25 & assignedDist != minDist,
                                       minDistClust, assigned))
    
        # Determine movement of cluster center from previous iteration
        Norm <- norm(as.matrix(centers$LATITUDE-NewCenters$LATITUDE, centers$LONGITUDE-NewCenters$LONGITUDE))
        #print(paste("Norm = ", Norm))

        if(Norm < 0.001) {
            converged <- 1
            break
        }
    
        if(looper == 1) {
            PlotCenters <- NewCenters
            PlotCenters$cluster <- 1:k
            PlotCenters$Iter <- looper
        } else {
            tempCenters <- NewCenters
            tempCenters$cluster <- 1:k
            tempCenters$Iter <- looper
            PlotCenters <- rbind(PlotCenters, tempCenters)
        }

        if(looper == iter) {
            #print("Warning: Did not converge")
        } else {
        centers <- NewCenters
        }
    }

print(paste("Ran ", looper, " iterations"))
```

Rescale Data for Plotting

```{r}
kdat$assigned %<>% as.factor()

# Rescale the data for the purposes of plotting
plotdata <- Data %>% transmute(LONGITUDE, LATITUDE)
plotdata$cluster <- kdat$assigned

# Rescale Plot Centers Data for plotting
PlotCenters$LATITUDE <- (PlotCenters$LATITUDE*sd(plotdata$LATITUDE))+mean(plotdata$LATITUDE)
PlotCenters$LONGITUDE <- (PlotCenters$LONGITUDE*sd(plotdata$LONGITUDE))+mean(plotdata$LONGITUDE)
plotdata <- rbind(plotdata %>% mutate(type = "Cencus Tract"), 
                  PlotCenters %>% transmute(LATITUDE, LONGITUDE, cluster, type = "Cluster Center"))
```

Below, we plot the resulting Equal-Sized K-Means clustered Congressional Districts. Note that the Census tracts are shown as smaller dots, while the cluster centers are shown as larger dots. The cluster centers corresponding to previous iterations are shown in higher transparency, allowing us to view the path of convergence of each cluster center.

```{r, fig.height=8, fig.width=10}
ggplot() +
  geom_point(data = PlotCenters, 
             aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster), 
                 alpha = as.numeric(Iter)),
             size = 5)  + 
  geom_point(data = plotdata,
           aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster),
               size = as.factor(type)), 
           alpha = 1/3) +
  labs(x = "Longitude (deg)", y = "Latitude (deg)", title = "Wisconsin Congressional Districts",
       subtitle = "Equal-Sized K-Means Clustering",
       color = "Clustered District",
       size = "Data Type",
       alpha = "Clustering Iteration") +
  scale_color_brewer(palette = "Dark2") +
  scale_size_manual(values = c(1, 5)) +
  theme_minimal()
```

A zoomed in view of the densest region of Census tracts (Milwaukee metropolitan region) is shown below:

```{r, fig.height=8, fig.width=10}
ggplot() +
  geom_point(data = PlotCenters, 
             aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster), 
                 alpha = as.numeric(Iter)),
             size = 5)  + 
  geom_point(data = plotdata,
           aes(x = LONGITUDE, y = LATITUDE, color = as.factor(cluster),
               size = as.factor(type)), 
           alpha = 1/3) +
  labs(x = "Longitude (deg)", y = "Latitude (deg)", 
       title = "Wisconsin Congressional Districts (Milwaukee Region)",
       subtitle = "Equal-Sized K-Means Clustering",
       color = "Clustered District",
       size = "Data Type",
       alpha = "Clustering Iteration") +
  scale_color_brewer(palette = "Dark2") +
  scale_size_manual(values = c(1, 5)) +
  scale_x_continuous(limits = c(-88.5, -87.5)) +
  scale_y_continuous(limits = c(42.8, 43.5)) +
  theme_minimal()
```

Finally, we plot the number of Census tracts per clustered Congressional district once more.

```{r}
ggplot(plotdata %>% group_by(cluster) %>% summarize(Count = n())) +
    geom_col(aes(x = as.factor(cluster), y = Count, fill = as.factor(cluster))) +
    labs(x = "Clustered District", y = "Number of Census Tracts") + 
    theme_minimal() +
    theme(legend.position="none") +
    scale_fill_brewer(palette = "Dark2")
```

The clustered districts consist of roughly equal counts of Census tracts.

```{r}
ggplot(PlotCongressDataMS %>% group_by(cluster) %>% summarize(Count = n())) +
    geom_col(aes(x = as.factor(cluster), y = Count, fill = as.factor(cluster))) +
    labs(x = "Clustered District", y = "Number of Census Tracts") + 
    theme_minimal() +
    theme(legend.position="none") +
    scale_fill_brewer(palette = "Dark2")
```

We have now found a solution that meets the following conditions required for our application:

- Automated algorithm
- Specific number of clusters (K = 8)
- Roughly equal cluster size


